<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Image Captioning RNN | Amirhossein Mahmoudi </title> <meta name="author" content="Amirhossein Mahmoudi"> <meta name="description" content="Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features."> <meta name="keywords" content="amirhossein-mahmoudi, mahmoudi, am_mahmoudi,"> <meta property="og:site_name" content="Amirhossein Mahmoudi"> <meta property="og:type" content="website"> <meta property="og:title" content="Amirhossein Mahmoudi | Image Captioning RNN"> <meta property="og:url" content="https://mamood.ir/projects/Image-Captioning-RNN/"> <meta property="og:description" content="Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features."> <meta property="og:image" content="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Image Captioning RNN"> <meta name="twitter:description" content="Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features."> <meta name="twitter:image" content="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output.png"> <meta name="twitter:site" content="@ammahmoodi"> <meta name="twitter:creator" content="@ammahmoodi"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Amirhossein Mahmoudi"
        },
        "url": "https://mamood.ir/projects/Image-Captioning-RNN/",
        "@type": "WebSite",
        "description": "Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features.",
        "headline": "Image Captioning RNN",
        
        "sameAs": ["https://orcid.org/0009-0006-8879-7932", "https://github.com/ammahmoudi", "https://telegram.me/am_mahmoudi", "https://www.linkedin.com/in/am-mahmoudi", "https://twitter.com/ammahmoodi", "https://instagram.com/am.mahmoudi"],
        
        "name": "Amirhossein Mahmoudi",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?35f4f1d9ccd51f0ffeea607d2b075320"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mamood.ir/projects/Image-Captioning-RNN/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Amirhossein</span> Mahmoudi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/portfolio/">Portfolio </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Image Captioning RNN</h1> <p class="post-description">Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features.</p> </header> <article> <div id="open-in-github"> <table class="table-cv list-group-table"> <tbody> <tr> <td class="list-group-name"><b> <a href="https://github.com/ammahmoudi/Image-Captioning-RNN" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i> This page is auto-generated. For more info and materials take a look at the original repository.</a> </b></td> </tr> </tbody> </table> </div> <hr> <p>Image Captioning using Recurrent Neural Networks on Flickr images with pretrained ResNet50 model features.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output-480.webp 480w,https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output-800.webp 800w,https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/output.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="result" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="data-documentation">Data Documentation</h2> <p>A new benchmark collection for sentence-based image description and search, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events. … The images were chosen from six different Flickr groups, and tend not to contain any well-known people or locations, but were manually selected to depict a variety of scenes and situations. For more information please read the <a href="https://www.kaggle.com/datasets/adityajn105/flickr8k" rel="external nofollow noopener" target="_blank">data documentation</a>.</p> <h2 id="code-explanation">Code Explanation</h2> <ul> <li> <strong>Import Libaries and Dataset</strong>: The code imports the necessary libraries such as TensorFlow, Keras, sklearn, etc. and downloads the Flickr8k dataset that contains images and captions.</li> <li> <strong>Creating Features and Captions Dictionary</strong>: The code uses a pretrained ResNet50 model to extract features from each image and stores them in a dictionary with the image ID as the key. It also reads the captions file and creates another dictionary with the image ID as the key and a list of captions as the value.</li> <li> <strong>Preprocessing and Tokenizing</strong>: The code cleans the captions text by converting to lowercase, removing punctuation, adding start and end tokens, etc. It also creates a tokenizer object that maps each word to an integer index and finds the maximum length of captions for padding.</li> <li> <strong>Data Generator</strong>: The code defines a data generator function that yields batches of input and output pairs for training the model. For each image and caption, it creates multiple samples by splitting the caption into partial sequences and encoding them using the tokenizer.</li> <li> <strong>Model</strong>: The code defines the image captioning model using Keras functional API. It consists of an encoder model that takes the image features and a sequence feature layer that takes the caption sequence as inputs, and a decoder model that combines them and produces a softmax output over the vocabulary size.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/architecture-480.webp 480w,https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/architecture-800.webp 800w,https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/architecture-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="https://raw.githubusercontent.com/ammahmoudi/Image-Captioning-RNN/main/architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="architecture" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <strong>Train</strong>: The code splits the data into train and test sets, creates a data generator for the train set, and trains the model for 20 epochs using categorical crossentropy loss and Adam optimizer.</li> <li> <strong>Test</strong>: The code loads the trained model and defines a function to generate captions for new images. It randomly selects some images from the test set, displays them, and shows the predicted captions along with the real captions and their similarity scores using BERT embeddings.</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Amirhossein Mahmoudi. Last updated: June 25, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-TNCS9B9B3L"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TNCS9B9B3L");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>